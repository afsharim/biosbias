{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T15:18:52.670104Z",
     "start_time": "2024-05-06T15:18:50.570133Z"
    }
   },
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import datasets\n",
    "import pickle\n",
    "\n",
    "print(datasets.__version__)\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(\"LabHC/bias_in_bios\", use_auth_token=\"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\")\n",
    "    all_data = concatenate_datasets([dataset['train'], dataset['test'], dataset['dev']])\n",
    "\n",
    "    # Define the filename\n",
    "    filename = 'BIOS.pkl'\n",
    "\n",
    "    # Open a file in write-binary mode\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(all_data, file)\n",
    "    print(\"Dataset downloaded and saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/milad/.cache/huggingface/datasets/LabHC___parquet/LabHC--bias_in_bios-0590f29daf9e7342/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09838bc39072449eb603d703f5211b98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and saved successfully!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:19:36.988018Z",
     "start_time": "2024-05-06T15:19:36.982690Z"
    }
   },
   "cell_type": "code",
   "source": "all_data",
   "id": "71acc9509650edff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['hard_text', 'profession', 'gender'],\n",
       "    num_rows: 396189\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:19:56.767413Z",
     "start_time": "2024-05-06T15:19:54.168809Z"
    }
   },
   "cell_type": "code",
   "source": "all_data['hard_text'][0]",
   "id": "1478b36d0c346b8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is also the project lead of and major contributor to the open source assembler/simulator \"EASy68K.\" He earned a masterâ€™s degree in computer science from the University of Michigan-Dearborn, where he is also an adjunct instructor. Downloads/Updates'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:21:04.764084Z",
     "start_time": "2024-05-06T15:21:04.742824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "# Define the filename\n",
    "filename = 'BIOS.pkl'\n",
    "\n",
    "try:\n",
    "    # Open the file in read-binary mode\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Load the data from the file\n",
    "        all_data_loaded = pickle.load(file)\n",
    "        print(\"Dataset loaded successfully!\")\n",
    "        # You can now use 'all_data' which should contain the dataset\n",
    "except FileNotFoundError:\n",
    "    print(f\"File '{filename}' not found.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))\n"
   ],
   "id": "a1f00424d1b07bef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:21:09.884383Z",
     "start_time": "2024-05-06T15:21:09.874399Z"
    }
   },
   "cell_type": "code",
   "source": "all_data_loaded",
   "id": "3724bc73183c17f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['hard_text', 'profession', 'gender'],\n",
       "    num_rows: 396189\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:25:07.625612Z",
     "start_time": "2024-05-06T15:25:07.488725Z"
    }
   },
   "cell_type": "code",
   "source": "!which python",
   "id": "741c4241a2f983a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/milad/anaconda3/envs/py38/bin/python\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:25:41.520290Z",
     "start_time": "2024-05-06T15:25:41.513122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random, glob, re\n",
    "import pickle as pkl\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "titles_to_ignore = {'real_estate_broker', 'landscape_architect', 'massage_therapist', 'magician', 'acupuncturist'} # close but not enough data on these titles :-(\n",
    "\n",
    "def save_pkl(obj, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pkl.dump(obj, f)\n",
    "        \n",
    "def load_pkl(filename, verbose=True):\n",
    "    if verbose:\n",
    "        print(f\"Loading '{filename}'\")\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pkl.load(f)"
   ],
   "id": "473332cdee3f4836",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:28:50.572631Z",
     "start_time": "2024-05-06T15:28:50.566690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process(p, replacement=\"_\"):\n",
    "    bio = p[\"raw\"][p[\"start_pos\"]:].strip()\n",
    "    names = p[\"name\"] \n",
    "    assert len(names)==3\n",
    "\n",
    "    regExp = r\"\\b(?:[Hh]e|[Ss]he|[Hh]er|[Hh]is|[Hh]im|[Hh]ers|[Hh]imself|[Hh]erself|[Mm][Rr]|[Mm][Rr][sS]|[Mm][Ss]|\"\n",
    "    regExp += \"|\".join([re.escape(n) for n in names if len(n)>0]) + r\")\\b\"\n",
    "    \n",
    "    bio = re.sub(regExp, replacement, bio)\n",
    "        \n",
    "    p[\"bio\"]=bio"
   ],
   "id": "ba9ff247f2d13bc7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:29:11.083900Z",
     "start_time": "2024-05-06T15:29:11.074849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_by(l, func):\n",
    "    ans = {}\n",
    "    for i in l:\n",
    "        k = func(i)\n",
    "        if k not in ans:\n",
    "            ans[k] = [i]\n",
    "        else:\n",
    "            ans[k].append(i)\n",
    "    return ans"
   ],
   "id": "4a7bfed53b558f82",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:39:23.262462Z",
     "start_time": "2024-05-06T15:39:23.253999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dedup_middle(bios): # remove triples where the middle name is a prefix of another middle name, so {Mary Lynn Doe, Mary L Doe, Mary Doe} => {Mary Lynn Doe}, but {Mary L Doe, Mary I Doe} => {Mary L Doe, Mary I Doe}\n",
    "    trips = group_by(bios, lambda b: (b[\"title\"], b[\"name\"][0], b[\"name\"][2]))\n",
    "    for k in trips:\n",
    "        to_remove = set()\n",
    "        if len(k)==1:\n",
    "            continue\n",
    "        for b1 in trips[k]:\n",
    "            for b2 in trips[k]:\n",
    "                if b1 is not b2 and b1[\"name\"][1].startswith(b2[\"name\"][1]):\n",
    "                    to_remove.add(b2[\"name\"][1])\n",
    "        if to_remove:\n",
    "            trips[k] = [b for b in trips[k] if b[\"name\"][1] not in to_remove]\n",
    "    return [b for v in trips.values() for b in v]"
   ],
   "id": "40cb82ee1fcdc1e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:39:23.785484Z",
     "start_time": "2024-05-06T15:39:23.781233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dedup(people): \n",
    "    by_name_title = group_by(people, lambda b: (b[\"name\"], b[\"title\"]))\n",
    "    ans = [sorted(ps, key = lambda p: (-len(p[\"raw\"]), p[\"raw\"], p[\"path\"]))[0] for ps in by_name_title.values()]\n",
    "    return ans"
   ],
   "id": "33ef3132ddb57243",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main(paths, output_filename):\n",
    "    all_people = [p for path in paths for p in load_pkl(path) if p[\"title\"] not in titles_to_ignore]\n",
    "    people = dedup_middle(dedup(all_people))\n",
    "    print(f\"{len(people):,}/{len(all_people):,} 'different' name+titles ({len(people)/len(all_people):.1%})\")\n",
    "    print(\"Processing bios...\")\n",
    "    for p in people:\n",
    "        process(p)\n",
    "    save_pkl(people, output_filename)\n",
    "    print(f\"Wrote {len(people):,} bios to '{output_filename}'\")\n",
    "    #if len(peoples)>1: # show overlaps\n",
    "    #    name_titles = [{(p[\"name\"][0], p[\"name\"][1], p[\"title\"]) for p in people} for people in peoples]\n",
    "    #    for path1, nts1 in zip(args.paths, name_titles):\n",
    "    #        for path2, nts2 in zip(args.paths, name_titles):\n",
    "    #            if path1<path2:\n",
    "    #                overlap2 = sum([nt in nts2 for nt in nts1])/len(nts1) + sum([nt in nts1 for nt in nts2])/len(nts2)\n",
    "    #                print(f\"{overlap2/2:.1%} overlap between {path1:20} and {path2:20}\")\n",
    "    #    output = dedup([p for ps in peoples for p in ps])\n",
    "    #else:\n",
    "    #    assert len(peoples)==1\n",
    "    #    output = peoples[0]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ArgumentParser(description='Dedup bios by name + title and add name field to records.')\n",
    "    parser.add_argument('paths', nargs='+', help='Path of bios .pkl file(s)', metavar=\"PATH\")\n",
    "    parser.add_argument(\"-o\", \"--output\", dest=\"output\", help=\"write bios to OUT.pkl\", metavar=\"OUT\", default=\"BIOS.pkl\")\n",
    "    args = parser.parse_args()\n",
    "    main(args.paths, args.output)\n"
   ],
   "id": "89c027157a00a728"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
